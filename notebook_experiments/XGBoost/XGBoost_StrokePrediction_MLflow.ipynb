{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZGOlGKDMpbU"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A8sTlyGfNq87"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "#s!pip install imbalanced-learn mlflow xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                           roc_auc_score, recall_score, f1_score,\n",
    "                           precision_score, average_precision_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jovyan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KLuK3dnbNsZH"
   },
   "outputs": [],
   "source": [
    "# Data Loading and Preprocessing\n",
    "df = pd.read_csv(\"work/notebook_experiments/healthcare-dataset-stroke-data.csv\")\n",
    "\n",
    "# Data Cleaning\n",
    "df[\"bmi\"] = df[\"bmi\"].fillna(df[\"bmi\"].median())\n",
    "df = df[df['gender'] != 'Other']\n",
    "\n",
    "# Feature Selection\n",
    "selected_features = ['gender', 'age', 'hypertension', 'heart_disease',\n",
    "                    'avg_glucose_level', 'bmi', 'smoking_status', 'stroke']\n",
    "df = df[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2Kq4P-czNzDw"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df_fe = df.copy()\n",
    "# 1. Age Grouping\n",
    "age_bins = [0, 50, 80, 120]\n",
    "age_labels = ['Young adult', 'Middle-aged', 'Very old']\n",
    "df_fe['age_group'] = pd.cut(df_fe['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# 2. BMI Categories\n",
    "bmi_bins = [0, 18.5, 25, 30, 35, 40, 100]\n",
    "bmi_labels = ['Underweight', 'Healthy Weight', 'Overweight', 'Class 1 Obesity', 'Class 2 Obesity', 'Class 3 Obesity']\n",
    "df_fe['bmi_category'] = pd.cut(df_fe['bmi'], bins=bmi_bins, labels=bmi_labels, right=False)\n",
    "\n",
    "# 3. Interaction Feature\n",
    "df_fe['age_hypertension'] = df_fe['age'] * df_fe['hypertension']\n",
    "\n",
    "# 4. Glucose Level Binning\n",
    "glucose_bins = [0, 70, 85, 100, 110, 126, 140, 300]\n",
    "glucose_labels = ['Hypoglycemia', 'Low Normal', 'Normal', 'Elevated', 'Pre-diabetic', 'Borderline Diabetic', 'Diabetic']\n",
    "df_fe['glucose_category'] = pd.cut(df_fe['avg_glucose_level'], bins=glucose_bins, labels=glucose_labels, right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6e47o1USN4QR"
   },
   "outputs": [],
   "source": [
    "# Defining categorical and numerical columns\n",
    "categorical_cols = ['gender', 'smoking_status','age_group', 'bmi_category', 'glucose_category']\n",
    "numerical_cols = [col for col in df_fe.columns if col not in categorical_cols + ['stroke']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n7J4sx91N6pG"
   },
   "outputs": [],
   "source": [
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i_0WmjD5N907"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X = df_fe.drop(columns=['stroke'])\n",
    "y = df_fe['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Calculate class weights\n",
    "scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wB5IZZiLODn-"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X = df_fe.drop(columns=['stroke'])\n",
    "y = df_fe['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Calculate class weights\n",
    "scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jM_7BeS6OO6G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/19 19:46:56 INFO mlflow.tracking.fluent: Experiment with name 'Stroke_Prediction_XGBoost' does not exist. Creating a new experiment.\n",
      "2025/06/19 19:46:56 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.4.2 <= xgboost <= 3.0.0, but the installed version is 3.0.2. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "# MLflow Experiment\n",
    "mlflow.set_experiment(\"Stroke_Prediction_XGBoost\")\n",
    "mlflow.xgboost.autolog()\n",
    "mlflow.set_tracking_uri(\"http://45.151.153.107:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVn8uE1jMrTe",
    "outputId": "31f6ab70-eda6-41ee-81b0-682c48911221"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/19 19:47:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBoost Classifier ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9831    0.6564    0.7872       972\n",
      "           1     0.1046    0.7800    0.1844        50\n",
      "\n",
      "    accuracy                         0.6624      1022\n",
      "   macro avg     0.5438    0.7182    0.4858      1022\n",
      "weighted avg     0.9401    0.6624    0.7577      1022\n",
      "\n",
      "ROC-AUC: 0.7833\n",
      "PR-AUC: 0.1485\n",
      "🏃 View run Stroke_Prediction_XGBoost_v1 at: http://45.151.153.107:5000/#/experiments/5/runs/518b9ba7660345d6b77ee1a53ca2ff61\n",
      "🧪 View experiment at: http://45.151.153.107:5000/#/experiments/5\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Stroke_Prediction_XGBoost_v1\"):\n",
    "    # Simplified approach - start with basic XGBoost before grid search\n",
    "    xgb_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='aucpr',\n",
    "            use_label_encoder=False,\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            n_estimators=100,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    mlflow.set_tag(\"mlflow.user\", \"Thato\")\n",
    "\n",
    "    # First verify the pipeline works without grid search\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_pipeline.predict(X_test)\n",
    "    y_proba = xgb_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc\n",
    "    })\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1\n",
    "    })\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(xgb_pipeline, \"XGBoost_Model.pkl\")\n",
    "    mlflow.sklearn.log_model(xgb_pipeline, \"xgboost_model\")\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n--- XGBoost Classifier ---\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    # Feature Importance\n",
    "    try:\n",
    "        xgb_model = xgb_pipeline.named_steps['classifier']\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        xgb.plot_importance(xgb_model, ax=ax)\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"feature_importance.png\")\n",
    "        mlflow.log_artifact(\"feature_importance.png\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate feature importance: {str(e)}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Stroke\", \"Stroke\"])\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", values_format='d')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
